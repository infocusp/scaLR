{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b3cbafc-1741-4535-91c1-75185c5afc08",
   "metadata": {},
   "source": [
    "Keypoints\n",
    "\n",
    "1. This notebook has been designed as a tutorial for using normalization from a scalr library.\n",
    "2. Also, we have compared results using standard library like sklearn, scanpy etc.\n",
    "3. These packages are built so to handle very large data say lakhs of samples with low resource constraints, which standard libraries can't handle at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6012f9b-e45a-4401-9349-0c1fa2a3c81a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21be67bc-29d0-44e4-a8a4-cfc7e3ca5645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/anand/bioc_repo/single_cell_classification/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de5a0712-dff6-4b01-a5cb-f248d944355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import anndata\n",
    "\n",
    "# scalr library normalization modules.\n",
    "from _scalr.data.preprocess import standard_scale, sample_norm\n",
    "\n",
    "# Scanpy library for sample-norm\n",
    "import scanpy as sc\n",
    "# Sklearn library for standard scaler object\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef2c7b-e7ae-44f4-b5e2-429f515d8108",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f10ace70-07fe-4c45-a32a-dd796cffd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed for reproducibility.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6523010-d479-4d2f-a3e8-9ec7bc3bd6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 10 × 4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anndata object is required for using pipeline normalization functions.\n",
    "train_adata = anndata.AnnData(X=np.random.rand(10, 4))\n",
    "train_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f57ff381-ed01-4a18-9c41-dded55f308bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5488135 , 0.71518937, 0.60276338, 0.54488318],\n",
       "       [0.4236548 , 0.64589411, 0.43758721, 0.891773  ],\n",
       "       [0.96366276, 0.38344152, 0.79172504, 0.52889492],\n",
       "       [0.56804456, 0.92559664, 0.07103606, 0.0871293 ],\n",
       "       [0.0202184 , 0.83261985, 0.77815675, 0.87001215],\n",
       "       [0.97861834, 0.79915856, 0.46147936, 0.78052918],\n",
       "       [0.11827443, 0.63992102, 0.14335329, 0.94466892],\n",
       "       [0.52184832, 0.41466194, 0.26455561, 0.77423369],\n",
       "       [0.45615033, 0.56843395, 0.0187898 , 0.6176355 ],\n",
       "       [0.61209572, 0.616934  , 0.94374808, 0.6818203 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "843863af-ee4d-4662-a428-a61f5b40f175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 5 × 4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating test anndata object.\n",
    "test_adata = anndata.AnnData(X=np.random.rand(5, 4))\n",
    "test_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b5f8caa-84be-40a9-8a5e-dbdf3d4affe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3595079 , 0.43703195, 0.6976312 , 0.06022547],\n",
       "       [0.66676672, 0.67063787, 0.21038256, 0.1289263 ],\n",
       "       [0.31542835, 0.36371077, 0.57019677, 0.43860151],\n",
       "       [0.98837384, 0.10204481, 0.20887676, 0.16130952],\n",
       "       [0.65310833, 0.2532916 , 0.46631077, 0.24442559]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_adata.X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b34e08-7022-4202-b993-31d33e25e47d",
   "metadata": {},
   "source": [
    "# 1. StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6053926-c6be-4fac-a32a-5fc0fa2a6f9e",
   "metadata": {},
   "source": [
    "## scalr package - how to to use it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00377fe1-fb3e-4558-a492-d5561187a29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Applying Standard Scaler normalization on data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. `fit()` function parameters : {'data': typing.Union[anndata._core.anndata.AnnData, anndata.experimental.multi_files._anncollection.AnnCollection], 'sample_chunksize': <class 'int'>, 'return': None}\n",
      "\n",
      "2. `transform()` function parameters : {'data': <class 'numpy.ndarray'>, 'return': <class 'numpy.ndarray'>}\n"
     ]
    }
   ],
   "source": [
    "# Creating object for standard scaling normalization.\n",
    "obj_ss = standard_scale.StandardScaler(with_mean=False)\n",
    "\n",
    "print('\\n1. `fit()` function parameters :', obj_ss.fit.__annotations__)\n",
    "print('\\n2. `transform()` function parameters :', obj_ss.transform.__annotations__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92cf9094-9a2c-4f96-a6cf-66f211c4d1f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Calculating mean of data...\n",
      "INFO:absl:Calculating standard deviation of data...\n",
      "INFO:absl:Setting `train_mean` to be zero, as `with_mean` is set to False!\n"
     ]
    }
   ],
   "source": [
    "# Fitting object on train data.\n",
    "## chunk size to process data in chunks - to extract required parameters from data. Enter value that can fit in your memory.\n",
    "## It can be 2k, 3k , 5k, 10k etc...\n",
    "sample_chunksize = 2\n",
    "obj_ss.fit(train_adata, sample_chunksize=sample_chunksize)\n",
    "\n",
    "# Transforming the test data using above created object.\n",
    "test_adata_pipeline = obj_ss.transform(test_adata.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36566aec-54ce-4c54-80c9-86a557418f29",
   "metadata": {},
   "source": [
    "## sklearn package for standardscaling\n",
    "- Developers can ignore this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a54c31bd-9de2-4772-ba68-405605d65cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79644353, 1.71130322, 1.45626525, 0.16287987],\n",
       "       [1.36937826, 2.43447219, 0.40712456, 0.32324491],\n",
       "       [0.64350622, 1.31152151, 1.09608649, 1.09235253],\n",
       "       [2.33021957, 0.42523965, 0.46401686, 0.46427603],\n",
       "       [1.39074325, 0.95334427, 0.93563236, 0.63540274]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard scaling using sklearn package\n",
    "std_scaler = StandardScaler(with_mean=False)\n",
    "std_scaler.fit(train_adata.X)\n",
    "test_adata_sklearn = std_scaler.transform(test_adata.X)\n",
    "test_adata_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a592691-0f87-4eb8-aee2-0af44623871e",
   "metadata": {},
   "source": [
    "## Comparing scalr library results with sklearn's library results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b269d5f-976e-4d99-8ae5-6f822fa7c68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if error is less than 1e-15\n",
    "abs(test_adata_sklearn - test_adata_pipeline) < 1e-15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c053b40b-d170-4666-b6ec-b6e1415f2fbb",
   "metadata": {},
   "source": [
    "# 2. SampleNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def9f30-1d9d-4167-9b18-bb2012b2c6b7",
   "metadata": {},
   "source": [
    "## scalr package - how to to use it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebaf5460-f7cd-4cbb-a3f8-502c5fb73861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Applying Sample-wise normalization on data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. `transform()` function parameters : {'data': <class 'numpy.ndarray'>, 'return': <class 'numpy.ndarray'>}\n"
     ]
    }
   ],
   "source": [
    "# Sample norm using pipeline\n",
    "obj_sample_norm = sample_norm.SampleNorm()\n",
    "\n",
    "print('\\n1. `transform()` function parameters :', obj_sample_norm.transform.__annotations__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18f0b716-ff8d-4ecb-9591-195217f9ac27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23128455, 0.2811586 , 0.4488116 , 0.03874524],\n",
       "       [0.39766289, 0.39997167, 0.12547318, 0.07689227],\n",
       "       [0.18687207, 0.21547646, 0.33780682, 0.25984466],\n",
       "       [0.67668801, 0.06986476, 0.14300702, 0.11044021],\n",
       "       [0.40386721, 0.15662972, 0.28835589, 0.15114718]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting is not required on train data for sample-norm.\n",
    "\n",
    "# Transforming on test data.\n",
    "test_data_sample_norm_pipeline = obj_sample_norm.transform(test_adata.X)\n",
    "test_data_sample_norm_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b86a86-7e97-4a40-85e3-6558c082c8f2",
   "metadata": {},
   "source": [
    "## Scanpy package for sample-norm\n",
    "- Developers can ignore this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d6bed81-105b-4f66-9c87-ca1ae5f60412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': array([[0.23128455, 0.2811586 , 0.4488116 , 0.03874524],\n",
       "        [0.39766289, 0.39997167, 0.12547318, 0.07689227],\n",
       "        [0.18687207, 0.21547646, 0.33780682, 0.25984466],\n",
       "        [0.67668801, 0.06986476, 0.14300702, 0.11044021],\n",
       "        [0.40386721, 0.15662972, 0.28835589, 0.15114718]]),\n",
       " 'norm_factor': array([1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample norm using scanpy package\n",
    "test_data_sample_norm_sc = sc.pp.normalize_total(test_adata, target_sum=1, inplace=False)\n",
    "test_data_sample_norm_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec3be1c-0031-49dc-8783-e1c769baf24d",
   "metadata": {},
   "source": [
    "## Comparing scalr library results with scanpy library results¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea3e91e9-50c8-49d5-a916-8620975e01d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if error is less than 1e-15\n",
    "abs(test_data_sample_norm_sc['X'] - test_data_sample_norm_pipeline) < 1e-15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scalr_minerva",
   "language": "python",
   "name": "scalr_minerva"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
