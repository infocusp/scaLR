{"cells":[{"cell_type":"markdown","metadata":{"id":"WZtTrD0KNRJy"},"source":["# <span style=\"color: steelblue;\">Batch Correction using scaLR</span>"]},{"cell_type":"markdown","metadata":{"id":"dEBM-AOGNRJ1"},"source":["Keypoints\n","\n","1. This notebook is designed as a tutorial for using batch correction using **`SimpleMetaDataLoader`** from **`scaLR`** library.\n","2. The dataloader is extensible to add any column from metadata as one hot-encoded vectors which can be useful for model training."]},{"cell_type":"markdown","metadata":{"id":"z90HlqMeNRJ2"},"source":["## <span style=\"color: steelblue;\">What is the batch correction?</span>\n","\n","- Single-cell genomic datasets related to a specific disease or trait are often compiled from multiple experiments, each sequenced from different single cells under varying conditions, such as capturing times, handling personnel, reagent lots, equipment, and even technology platforms.\n","- These differences lead to large variations also known as `batch effects` in the data. When combining these datasets for analysis and modeling, it's crucial to ensure that the model isn't biased towards data from certain batches due to their higher or lower value ranges. Therefore, it's necessary to eliminate `batch effects` from these datasets.\n","\n","\n","## <span style=\"color: steelblue;\">How to perform batch correction?</span>\n","\n","- Many statistical tools such as `Scanpy`, `Seurat`, `Harmony`, `Combat`, etc. performed `batch correction` by performing `normalization` and `dimensional reduction` and then removing the `batch effect` by fitting `linear or mixed models`, calculating the `k-nearest neighbor` or `mutual nearest neighbors distance`, `canonical correlation analysis`, etc.\n","\n","- While traditional `batch corrections` are robust and widely used, they have limitations in handling non-linear relationships, scalability, flexibility, and the preservation of biological signals, AI/ML-based batch correction methods offer significant advantages in these areas, making them a powerful alternative in complex and large-scale single-cell genomic datasets.\n","\n","- The `batch correction` approach in the **`scaLR`** platform is inspired by the [scGPT](https://www.nature.com/articles/s41592-024-02201-0)(Cui et al.) tool, where batch information is integrated into the feature data to inform the model about the origin of each sample. Since batch is a `categorical` variable, directly including it as a `label-encoded` feature is not appropriate, as no batch is inherently superior to another. Instead, the solution is to use a `one-hot encoded vector` to represent batch information.\n","\n","- For example, if we have four batches in the dataset, the one-hot encoding would work as follows:\n","    - Batch 1 -> 0 0 0 1\n","    - Batch 2 -> 0 0 1 0\n","    - Batch 3 -> 0 1 0 0\n","    - Batch 4 -> 1 0 0 0\n","\n","- These encoded vectors represent the batches and are added to the feature data. In this case, four additional columns will be included in the feature data, ensuring that the model is aware of the batch information while training on samples from different batches.\n","\n","\n","## <span style=\"color: steelblue;\">How is it implemented in the scaLR platform?</span>\n","\n","- In the **`scaLR`** platform, we've implemented **`SimpleMetaDataLoader`** data loader that handles this process automatically.\n","- You can specify the `metadata` column you want to one-hot encode and add it to the feature data, and the data loader will take care of the encoding.\n","- We've also extended the functionality to allow users to include multiple columns from the `metadata` as `one-hot encoded vectors` in the feature data. Bypassing a list of columns, you can easily incorporate additional information.\n","- This approach is particularly useful in scenarios like predicting `disease vs. non-disease` outcomes, where certain `metadata`, such as `cell type`, might enhance the model's predictive power.\n","- By adding the `cell type` information to the feature data using this method, you can improve the model's performance.\n","- Generally, this won't be used as a library utility - it will be mostly used as a part of pipeline. Please find below a explaination a code snippet to understand its basics.\n"]},{"cell_type":"markdown","source":["## <span style=\"color: steelblue;\">Cloning scaLR</span>"],"metadata":{"id":"Lyk1yNRW9iMI"}},{"cell_type":"code","source":["!git clone https://github.com/infocusp/scaLR.git"],"metadata":{"id":"ufzA5OylNWsA","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## <span style=\"color: steelblue;\">Library Installation and Imports</span>\n","\n"],"metadata":{"id":"__FIQG1T9r-V"}},{"cell_type":"code","source":["!pip install anndata==0.10.9 pydeseq2==0.4.11 scanpy==1.10.3"],"metadata":{"collapsed":true,"id":"59UdOT0nRro6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZwdNgQ7NRJ4"},"outputs":[],"source":["# Required imports.\n","import sys\n","sys.path.append('./scaLR')\n","\n","import anndata\n","import numpy as np\n","import pandas as pd\n","\n","from scalr.nn.dataloader import build_dataloader, simple_metadataloader\n","\n","# Setting seed for reproducibility\n","np.random.seed(0)"]},{"cell_type":"markdown","source":["## <span style=\"color: steelblue;\">Downloading data</span>\n","\n","For this tutorial, we will use two datasets from `cellxgene`([Jin et al. (2021) iScience](https://doi.org/10.1016/j.isci.2021.103115)). The first dataset will serve as batch 1, and the second as batch 2."],"metadata":{"id":"RgQ7PSXy_dtY"}},{"cell_type":"code","source":["!wget -P ./data https://datasets.cellxgene.cziscience.com/16acb1d0-4108-4767-9615-0b42abe09992.h5ad\n","!wget -P ./data https://datasets.cellxgene.cziscience.com/8651e63c-0f98-4a87-bdbd-2da41bdf6de5.h5ad"],"metadata":{"id":"xYf5O0MbdcJ7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## <span style=\"color: steelblue;\">Loading datasets and merging</span>"],"metadata":{"id":"6wZhhGrwClT7"}},{"cell_type":"code","source":["data_1 = anndata.read_h5ad('/content/data/16acb1d0-4108-4767-9615-0b42abe09992.h5ad')\n","data_2 = anndata.read_h5ad('/content/data/8651e63c-0f98-4a87-bdbd-2da41bdf6de5.h5ad')\n","print(f'\\nDataset-1 has {data_1.n_obs} cells and {data_1.n_vars} genes\\nDataset-2 has {data_2.n_obs} cells and {data_2.n_vars} genes')"],"metadata":{"id":"u8fBz_7Zdc7g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'Shape of \"obs\" before adding batch\\n\\nDataset-1 : {data_1.obs.shape}\\nDataset-2 : {data_2.obs.shape}')"],"metadata":{"id":"R1_oqEnRDBEu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Adding batch information.\n","data_1.obs['batch'] = 'batch1'\n","data_2.obs['batch'] = 'batch2'\n","print(f'Shape of \"obs\" after adding batch\\n\\nDataset-1 : {data_1.obs.shape}\\nDataset-2 : {data_2.obs.shape}')"],"metadata":{"id":"5OZ99T9jfOMR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Combining two datasets.\n","adata = anndata.concat([data_1, data_2])\n","print(f'Combined datset has shape : {adata.shape}')"],"metadata":{"id":"g1urx3oLfcLY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## <span style=\"color: steelblue;\">Batch correction</span>"],"metadata":{"id":"ZJTpOrIXGcAK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUMPGYJ-NRJ5"},"outputs":[],"source":["# Below are the required params for SimpleMetaDataLoader.\n","simple_metadataloader.SimpleMetaDataLoader.__init__.__annotations__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kmCGPXeLNRJ6"},"outputs":[],"source":["# Defining required parameters for SimpleMetaDataLoader.\n","\n","# For batch correction you can pass the `batch` column inside `metadata_col`.\n","metadata_col = ['batch', ]\n","\n","# Generating mappings for anndata obs columns.\n","mappings = {}\n","for column_name in adata.obs.columns:\n","    mappings[column_name] = {}\n","\n","    id2label = []\n","    id2label += adata.obs[column_name].astype(\n","        'category').cat.categories.tolist()\n","\n","    label2id = {id2label[i]: i for i in range(len(id2label))}\n","    mappings[column_name]['id2label'] = id2label\n","    mappings[column_name]['label2id'] = label2id"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BtTzBQ8oNRJ6"},"outputs":[],"source":["# Creating dataloader object.\n","dataloader = simple_metadataloader.SimpleMetaDataLoader(batch_size=3,\n","                                                        target='cell_type',\n","                                                        mappings=mappings,\n","                                                        metadata_col=metadata_col)"]},{"cell_type":"markdown","source":["We can check if `batch` is added as a one hot-encoded vectors in features data`(i.e. 23586 genes + 2 batches)`.\n","Initially features shape is `(batch_size, 23586)` & there are 2 batches in data.\n","So number of features after adding this column to features data should be `23586+2=23588`.\n","Hence features shape has to be `(batch_size, 23588)` post doing batch correction."],"metadata":{"id":"gzv3mvFYOl5S"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1O2AyKFxNRJ6"},"outputs":[],"source":["# Verifying features in the dataloader\n","for feature, _ in dataloader(adata):\n","    print('Features shape :', feature.shape)\n","    print('Features :', feature)\n","    break"]},{"cell_type":"markdown","source":["We observe that the feature tensor has a shape of `[3, 23588]`, representing `3` samples with `23,588` features each. The batch information is appended to the gene expression values using one-hot encoding: in this case, each feature vector ends with values `[1, 0]`, representing the samples from `batch 1`."],"metadata":{"id":"OVeWJS8h_Ctu"}},{"cell_type":"code","source":["# Checking what is one hot encoding vector for batches.\n","onhotencode_batches = dataloader.metadata_onehotencoder['batch'].transform(np.array(['batch1', 'batch2']).reshape(-1, 1))\n","onhotencode_batches.A"],"metadata":{"id":"WiQYdHjhzoIW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["It has been verified that the one-hot encoding vector for batch 1 is [1, 0] and for batch 2 is [0, 1]"],"metadata":{"id":"7t9oD5BoBl1t"}},{"cell_type":"code","source":[],"metadata":{"id":"1LHHx8A1CJf7"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"scalr_minerva","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.19"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}